"""
í™”ë©´ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤
Zep í™”ë©´ì„ ìº¡ì²˜í•˜ì—¬ í•™ìƒ ì´ë¦„ê³¼ ì–¼êµ´ì„ ê°ì§€í•©ë‹ˆë‹¤.
"""
import cv2
import numpy as np
import mss
import pytesseract
import asyncio
from datetime import datetime
from typing import List, Optional, Set
from difflib import get_close_matches

try:
    from Levenshtein import distance as levenshtein_distance
    LEVENSHTEIN_AVAILABLE = True
except ImportError:
    LEVENSHTEIN_AVAILABLE = False
    print("âš ï¸ python-Levenshteinì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ë¦„ ë§¤ì¹­ ì •í™•ë„ê°€ ë‚®ì•„ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

from config import config
from database import DBService


class ScreenMonitor:
    """í™”ë©´ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, discord_bot):
        """
        í™”ë©´ ëª¨ë‹ˆí„°ë§ ì´ˆê¸°í™”
        
        Args:
            discord_bot: DiscordBot ì¸ìŠ¤í„´ìŠ¤
        """
        self.discord_bot = discord_bot
        self.db_service = DBService()
        self.is_running = False
        
        # ì–¼êµ´ ê°ì§€ ëª¨ë¸ ì´ˆê¸°í™”
        try:
            self.face_cascade = cv2.CascadeClassifier(
                cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
            )
            if self.face_cascade.empty():
                raise Exception("ì–¼êµ´ ê°ì§€ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âŒ ì–¼êµ´ ê°ì§€ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.face_cascade = None
        
        # ì„¤ì •
        self.check_interval = config.SCREEN_CHECK_INTERVAL
        self.threshold = config.FACE_DETECTION_THRESHOLD
        self.start_time = None  # ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œê°„
        self.warmup_minutes = 1  # ì›Œë°ì—… ì‹œê°„ (ë¶„)
        
        print("âœ… í™”ë©´ ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    async def start(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        if not config.SCREEN_MONITOR_ENABLED:
            print("â„¹ï¸ í™”ë©´ ëª¨ë‹ˆí„°ë§ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤. (.envì—ì„œ SCREEN_MONITOR_ENABLED=trueë¡œ ì„¤ì •)")
            return
        
        if not self.face_cascade:
            print("âŒ ì–¼êµ´ ê°ì§€ ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ í™”ë©´ ëª¨ë‹ˆí„°ë§ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        self.is_running = True
        self.start_time = datetime.now()  # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        
        print(f"ğŸ‘ï¸ í™”ë©´ ëª¨ë‹ˆí„°ë§ ì‹œì‘ (ì²´í¬ ê°„ê²©: {self.check_interval}ì´ˆ / {self.check_interval//60}ë¶„)")
        print(f"   â€¢ ê°ì§€ ì°¨ì´ ì„ê³„ê°’: {self.threshold}ëª…")
        print(f"   â€¢ ì›Œë°ì—… ì‹œê°„: {self.warmup_minutes}ë¶„ (ì‹œì‘ í›„ ì•Œë¦¼ ì•ˆ ë³´ëƒ„)")
        
        while self.is_running:
            try:
                await self._check_screen()
                await asyncio.sleep(self.check_interval)
            except Exception as e:
                print(f"âŒ í™”ë©´ ëª¨ë‹ˆí„°ë§ ì¤‘ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(self.check_interval)
    
    async def stop(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.is_running = False
        print("ğŸ›‘ í™”ë©´ ëª¨ë‹ˆí„°ë§ ì¤‘ì§€")
    
    async def _check_screen(self):
        """í™”ë©´ ì²´í¬ ì‹¤í–‰"""
        # ì›Œë°ì—… ì‹œê°„ ì²´í¬ (í”„ë¡œê·¸ë¨ ì‹œì‘ ì§í›„ ì•Œë¦¼ ë°©ì§€)
        if self.start_time:
            elapsed = (datetime.now() - self.start_time).total_seconds() / 60
            if elapsed < self.warmup_minutes:
                # ì¡°ìš©íˆ ìŠ¤í‚µ
                return
        
        current_time = datetime.now().strftime("%H:%M")
        print(f"\nğŸ” [{current_time}] í™”ë©´ ì²´í¬ ì‹œì‘...")
        
        # 1. DBì—ì„œ ì¹´ë©”ë¼ ON í•™ìƒ ì¡°íšŒ
        camera_on_students = await self.db_service.get_camera_on_students()
        
        if not camera_on_students:
            print("   â„¹ï¸ ì¹´ë©”ë¼ ON ìƒíƒœì¸ í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        expected_count = len(camera_on_students)
        student_names = [s.zep_name for s in camera_on_students]
        print(f"   ğŸ“Š ì¹´ë©”ë¼ ON í•™ìƒ: {expected_count}ëª…")
        print(f"   ğŸ‘¥ {', '.join(student_names)}")
        
        # 2. í™”ë©´ ìº¡ì²˜ ë° ë¶„ì„
        try:
            frame = self.capture_screen()
            if frame is None:
                print("   âŒ í™”ë©´ ìº¡ì²˜ ì‹¤íŒ¨")
                return
            
            # 3. í™”ë©´ì—ì„œ ì´ë¦„ + ì–¼êµ´ ê°ì§€
            detected_names = self.detect_students_on_screen(frame, student_names)
            detected_count = len(detected_names)
            
            print(f"   ğŸ¯ í™”ë©´ì—ì„œ ê°ì§€: {detected_count}ëª…")
            if detected_names:
                print(f"   âœ… ê°ì§€ëœ í•™ìƒ: {', '.join(detected_names)}")
            
            # 4. ì°¨ì´ í™•ì¸
            missing_count = expected_count - detected_count
            
            if missing_count >= self.threshold:
                # ëˆ„ê°€ ì—†ëŠ”ì§€ íŒŒì•…
                missing_students = [name for name in student_names if name not in detected_names]
                
                print(f"   âš ï¸ {missing_count}ëª… ë¶€ì¬ ê°ì§€!")
                print(f"   âŒ ë¯¸ê°ì§€ í•™ìƒ: {', '.join(missing_students)}")
                
                # ê°•ì‚¬ì—ê²Œ ì•Œë¦¼
                await self._notify_instructor_about_missing(
                    camera_on_students,
                    detected_names,
                    missing_students
                )
            else:
                print(f"   âœ… ì •ìƒ (ì°¨ì´: {missing_count}ëª…, ì„ê³„ê°’: {self.threshold}ëª…)")
        
        except Exception as e:
            print(f"   âŒ í™”ë©´ ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def capture_screen(self) -> Optional[np.ndarray]:
        """
        í™”ë©´ ìº¡ì²˜
        
        Returns:
            ìº¡ì²˜ëœ í™”ë©´ ì´ë¯¸ì§€ (numpy array) ë˜ëŠ” None
        """
        try:
            with mss.mss() as sct:
                # ë©”ì¸ ëª¨ë‹ˆí„° ìº¡ì²˜
                monitor = sct.monitors[1]
                screenshot = sct.grab(monitor)
                
                # numpy arrayë¡œ ë³€í™˜
                img = np.array(screenshot)
                
                # BGRA â†’ BGR ë³€í™˜ (OpenCV í˜•ì‹)
                frame = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
                
                return frame
        except Exception as e:
            print(f"âŒ í™”ë©´ ìº¡ì²˜ ì˜¤ë¥˜: {e}")
            return None
    
    def detect_students_on_screen(self, frame: np.ndarray, student_names: List[str]) -> Set[str]:
        """
        í™”ë©´ì—ì„œ í•™ìƒ ì´ë¦„ + ì–¼êµ´ ê°ì§€
        
        Args:
            frame: ìº¡ì²˜ëœ í™”ë©´
            student_names: ê°ì§€í•  í•™ìƒ ì´ë¦„ ëª©ë¡
            
        Returns:
            ê°ì§€ëœ í•™ìƒ ì´ë¦„ ì§‘í•©
        """
        detected = set()
        
        # ë°©ë²• 1: OCRë¡œ ì´ë¦„ ì°¾ê¸° (ì‹œë„)
        detected_by_ocr = self._detect_by_ocr(frame, student_names)
        detected.update(detected_by_ocr)
        
        # ë°©ë²• 2: ì–¼êµ´ ê°œìˆ˜ë¡œ ì¶”ì • (OCR ì‹¤íŒ¨ ì‹œ)
        if len(detected) == 0:
            face_count = self._count_faces(frame)
            print(f"   â„¹ï¸ OCR ì‹¤íŒ¨, ì–¼êµ´ ê°œìˆ˜ë§Œ ì¹´ìš´íŠ¸: {face_count}ê°œ")
            # ì–¼êµ´ ê°œìˆ˜ë§Œí¼ í•™ìƒì´ ìˆë‹¤ê³  ê°€ì • (ëˆ„êµ°ì§€ëŠ” ëª¨ë¦„)
            # ì´ ê²½ìš° ì°¨ì´ë§Œ ê³„ì‚° ê°€ëŠ¥
            return set(student_names[:face_count])  # ì„ì‹œë¡œ ì•ì—ì„œë¶€í„° ì±„ì›€
        
        return detected
    
    def _detect_by_ocr(self, frame: np.ndarray, student_names: List[str]) -> Set[str]:
        """
        OCRë¡œ í™”ë©´ì—ì„œ í•™ìƒ ì´ë¦„ ì°¾ê¸°
        
        Args:
            frame: ìº¡ì²˜ëœ í™”ë©´
            student_names: í•™ìƒ ì´ë¦„ ëª©ë¡
            
        Returns:
            ê°ì§€ëœ í•™ìƒ ì´ë¦„ ì§‘í•©
        """
        detected = set()
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì—¬ëŸ¬ ë°©ë²•)
            processed_images = self._preprocess_for_ocr(frame)
            
            all_texts = []
            
            # ì—¬ëŸ¬ ì „ì²˜ë¦¬ ë°©ë²•ìœ¼ë¡œ OCR ì‹œë„
            for i, processed in enumerate(processed_images):
                try:
                    # Tesseract OCR ì‹¤í–‰
                    custom_config = r'--oem 3 --psm 11'
                    text = pytesseract.image_to_string(
                        processed,
                        lang='kor+eng',
                        config=custom_config
                    )
                    all_texts.append(text)
                except Exception as e:
                    print(f"   âš ï¸ OCR ì‹œë„ {i+1} ì‹¤íŒ¨: {e}")
            
            # OCR ê²°ê³¼ì—ì„œ í•™ìƒ ì´ë¦„ ì°¾ê¸°
            for text in all_texts:
                for student_name in student_names:
                    # í•™ìƒ ì´ë¦„ì´ OCR ê²°ê³¼ì— ìˆëŠ”ì§€ í™•ì¸
                    if self._match_name_in_text(student_name, text, student_names):
                        detected.add(student_name)
        
        except Exception as e:
            print(f"   âš ï¸ OCR ê°ì§€ ì˜¤ë¥˜: {e}")
        
        return detected
    
    def _preprocess_for_ocr(self, image: np.ndarray) -> List[np.ndarray]:
        """
        OCRì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì—¬ëŸ¬ ë°©ë²•)
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            
        Returns:
            ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
        """
        results = []
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # ë°©ë²• 1: í•´ìƒë„ 2ë°° ì—…ìŠ¤ì¼€ì¼ + Otsu ì´ì§„í™”
        resized = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)
        denoised = cv2.fastNlMeansDenoising(resized, None, 10, 7, 21)
        _, binary1 = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        results.append(binary1)
        
        # ë°©ë²• 2: CLAHE + ì´ì§„í™”
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(gray)
        _, binary2 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        results.append(binary2)
        
        # ë°©ë²• 3: ì–´ëŒ‘í‹°ë¸Œ ì´ì§„í™”
        adaptive = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 11, 2
        )
        results.append(adaptive)
        
        return results
    
    def _match_name_in_text(self, student_name: str, ocr_text: str, all_student_names: List[str]) -> bool:
        """
        OCR í…ìŠ¤íŠ¸ì—ì„œ í•™ìƒ ì´ë¦„ ë§¤ì¹­
        
        Args:
            student_name: ì°¾ì„ í•™ìƒ ì´ë¦„
            ocr_text: OCR ê²°ê³¼ í…ìŠ¤íŠ¸
            all_student_names: ì „ì²´ í•™ìƒ ëª…ë‹¨
            
        Returns:
            ë§¤ì¹­ ì—¬ë¶€
        """
        # ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        clean_text = ''.join(c for c in ocr_text if c.isalnum() or ord('ê°€') <= ord(c) <= ord('í£'))
        
        # ì™„ì „ ì¼ì¹˜
        if student_name in clean_text:
            return True
        
        # ìœ ì‚¬ë„ ë§¤ì¹­ (get_close_matches)
        words = ocr_text.split()
        matches = get_close_matches(student_name, words, n=1, cutoff=0.8)
        if matches:
            return True
        
        # Levenshtein ê±°ë¦¬ (1~2ê¸€ì ì°¨ì´ í—ˆìš©)
        if LEVENSHTEIN_AVAILABLE:
            for word in words:
                clean_word = ''.join(c for c in word if c.isalnum() or ord('ê°€') <= ord(c) <= ord('í£'))
                if clean_word and levenshtein_distance(student_name, clean_word) <= 1:
                    return True
        
        return False
    
    def _count_faces(self, frame: np.ndarray) -> int:
        """
        í™”ë©´ì—ì„œ ì–¼êµ´ ê°œìˆ˜ ì„¸ê¸°
        
        Args:
            frame: ìº¡ì²˜ëœ í™”ë©´
            
        Returns:
            ê°ì§€ëœ ì–¼êµ´ ê°œìˆ˜
        """
        if not self.face_cascade:
            return 0
        
        try:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            
            # ì–¼êµ´ ê°ì§€
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(30, 30)
            )
            
            return len(faces)
        except Exception as e:
            print(f"   âš ï¸ ì–¼êµ´ ê°ì§€ ì˜¤ë¥˜: {e}")
            return 0
    
    async def _notify_instructor_about_missing(
        self,
        camera_on_students: List,
        detected_names: Set[str],
        missing_students: List[str]
    ):
        """
        ê°•ì‚¬ì—ê²Œ ë¶€ì¬ í•™ìƒ ì•Œë¦¼
        
        Args:
            camera_on_students: ì¹´ë©”ë¼ ON í•™ìƒ ë¦¬ìŠ¤íŠ¸
            detected_names: í™”ë©´ì—ì„œ ê°ì§€ëœ ì´ë¦„
            missing_students: ë¯¸ê°ì§€ í•™ìƒ ì´ë¦„
        """
        if not config.INSTRUCTOR_CHANNEL_ID:
            print("   âš ï¸ ê°•ì‚¬ ì±„ë„ IDê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        try:
            import discord
            
            channel = self.discord_bot.get_channel(int(config.INSTRUCTOR_CHANNEL_ID))
            
            if not channel:
                print(f"   âŒ ê°•ì‚¬ ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config.INSTRUCTOR_CHANNEL_ID}")
                return
            
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M")
            
            embed = discord.Embed(
                title="ğŸš¨ í™”ë©´ ëª¨ë‹ˆí„°ë§ ì•Œë¦¼",
                description="í•™ìƒë“¤ì´ í™”ë©´ì—ì„œ ê°ì§€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                color=discord.Color.red()
            )
            
            embed.add_field(
                name="ğŸ“Š ì¹´ë©”ë¼ ON",
                value=f"{len(camera_on_students)}ëª…",
                inline=True
            )
            
            embed.add_field(
                name="ğŸ¯ í™”ë©´ ê°ì§€",
                value=f"{len(detected_names)}ëª…",
                inline=True
            )
            
            embed.add_field(
                name="âŒ ë¯¸ê°ì§€",
                value=f"{len(missing_students)}ëª…",
                inline=True
            )
            
            # ë¯¸ê°ì§€ í•™ìƒ ëª©ë¡
            if missing_students:
                missing_list = "\n".join([f"â€¢ {name}" for name in missing_students])
                embed.add_field(
                    name="ğŸ”´ ë¯¸ê°ì§€ í•™ìƒ ëª…ë‹¨",
                    value=missing_list,
                    inline=False
                )
            
            embed.set_footer(text=f"ì²´í¬ ì‹œê°„: {current_time}")
            
            await channel.send(embed=embed)
            
            print(f"   ğŸ“¢ ê°•ì‚¬ ì±„ë„ì— ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
            
        except Exception as e:
            print(f"   âŒ ê°•ì‚¬ ì±„ë„ ì•Œë¦¼ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

